{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This notebook ONLY does the data checks - it is a utility for just re-running that section of the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PC: \n",
    "database_dir = r\"E:\\TriNetX\\\\\"   # Location where the database files are stored \n",
    "working_dir = r\"C:\\Users\\reblo\\Box\\Residency Personal Files\\Scholarly Work\\Locke Research Projects\\TriNetX Code\\Hypercapnia TriNetX CSV Processing\\Working\\\\\" #location where to read and right from (faster = better if space allows)\n",
    "\n",
    "#Mac \n",
    "#database_dir = r\"/Volumes/LOCKE STUDY/TriNetX\"   # Location where the database files are stored \n",
    "#working_dir = r\"/Users/blocke/TriNetX Working/\"\n",
    "\n",
    "# These are commented out as they are handed to the master script\n",
    "# AMBULATORY, EMERGENCY, or INPATIENT\n",
    "output_dirs = [\"AMBULATORY\", \"EMERGENCY\", \"INPATIENT\"]\n",
    "\n",
    "#\"AMB\" \"EMER\" or \"INPAT\" - or comment out if calling externally\n",
    "settings = [\"AMB\", \"EMER\", \"INPAT\"] \n",
    "\n",
    "#ABG, VBG, OBESITY, PREDISPOSITION, RESPFAIL, VENTSUPPORT\n",
    "rfss = [\"ABG\", \"VBG\", \"OBESITY\", \"PREDISPOSITION\", \"RESPFAIL\", \"VENTSUPPORT\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import gc\n",
    "\n",
    "#Create an output directory if it's not already there\n",
    "for output_dir in output_dirs: \n",
    "    os.makedirs(os.path.join(working_dir[:-1], \"output\", output_dir), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_check(output_dir, setting, rfs):\n",
    "    start_time = time.time()\n",
    "    #RFS_ABG_ENC_AMB_BEFORE = pd.read_csv(os.path.join(working_dir[:-1], \"output\", output_dir, \"RFS_\"+rfs+\"_ENC_\"+setting+\"_BEFORE.csv\"))\n",
    "    chunk_size = 100000  # you can adjust the chunk size as needed\n",
    "    # Initialize an empty list to hold the data\n",
    "    data_chunks = []\n",
    "    # Read the file in chunks\n",
    "    for chunk in pd.read_csv(os.path.join(working_dir[:-1], \"output\", output_dir, \"RFS_\"+rfs+\"_ENC_\"+setting+\"_BEFORE.csv\", chunksize=chunk_size)):\n",
    "        data_chunks.append(chunk)   \n",
    "    RFS_ABG_ENC_AMB_BEFORE = pd.concat(data_chunks, ignore_index=True)\n",
    "    del chunks\n",
    "    # Filter out patients who did not pass the data quality check\n",
    "    if setting == \"AMB\":\n",
    "        new_OP_data_quality_check_FINAL_patients = list(pd.read_csv(os.path.join(working_dir[:-1], \"data_checks\", \"amb_enc_screen.csv\"))[\"encounter_id\"])\n",
    "        print(\"Number of Unique Encounters in OP Filter:\", len(new_OP_data_quality_check_FINAL_patients))\n",
    "        print(\"Prefilter: \")\n",
    "        print(RFS_ABG_ENC_AMB_BEFORE.shape)\n",
    "        RFS_ABG_ENC_AMB_BEFORE = RFS_ABG_ENC_AMB_BEFORE[RFS_ABG_ENC_AMB_BEFORE[\"encounter_id\"].isin(new_OP_data_quality_check_FINAL_patients)]\n",
    "    else: \n",
    "        new_IP_data_quality_check_FINAL_patients = list(pd.read_csv(os.path.join(working_dir[:-1], \"data_checks\", \"inp_enc_screen.csv\"))[\"encounter_id\"])\n",
    "\n",
    "        #new_IP_data_quality_check_FINAL_patients = list(set(unique_vs_encounters) & set(unique_diag_encounters) & set(unique_med_encounters) & set(unique_proc_encounters) & set(unique_lab_encounters))\n",
    "        print(\"Number of Unique Encounters in IP Filter:\", len(new_IP_data_quality_check_FINAL_patients))\n",
    "        print(\"Prefilter: \")\n",
    "        print(RFS_ABG_ENC_AMB_BEFORE.shape)\n",
    "        RFS_ABG_ENC_AMB_BEFORE = RFS_ABG_ENC_AMB_BEFORE[RFS_ABG_ENC_AMB_BEFORE[\"encounter_id\"].isin(new_IP_data_quality_check_FINAL_patients)]\n",
    "\n",
    "    print(\"\\n\")\n",
    "    display(RFS_ABG_ENC_AMB_BEFORE.head())\n",
    "    print(RFS_ABG_ENC_AMB_BEFORE.shape)\n",
    "    print(RFS_ABG_ENC_AMB_BEFORE.isna().sum().sum())\n",
    "\n",
    "    RFS_ABG_ENC_AMB_BEFORE.to_csv(os.path.join(working_dir[:-1], \"output\", output_dir, \"RFS_\"+rfs+\"_ENC_\"+setting+\"_AFTER.csv\"), index = False) \n",
    "\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    hours = int(execution_time // 3600)\n",
    "    minutes = int((execution_time % 3600) // 60)\n",
    "    seconds = execution_time % 60\n",
    "    print(f\"Executed in {hours} hours, {minutes} minutes, and {seconds:.2f} seconds.\")\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ambulatory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (958042817.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 2\u001b[1;36m\u001b[0m\n\u001b[1;33m    AMBULATORY, AMB, and\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "#test \n",
    "\n",
    "data_check(output_dirs[0], settings[0], \"PREDISPOSITION\")\n",
    "\n",
    "\"\"\"\n",
    "for rfs in rfss:\n",
    "    print(f\"Executing {output_dirs[0]}, {settings[0]}, and {rfs}.\")\n",
    "    data_check(output_dirs[0], settings[0], rfs)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emergency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rfs in rfss:\n",
    "    print(f\"Executing {output_dirs[1]}, {settings[1]}, and {rfs}.\")\n",
    "    data_check(output_dirs[1], settings[1], rfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inpatient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rfs in rfss:\n",
    "    print(f\"Executing {output_dirs[1]}, {settings[1]}, and {rfs}.\")\n",
    "    data_check(output_dirs[2], settings[2], rfs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
